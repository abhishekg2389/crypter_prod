{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T17:48:21.296042Z",
     "start_time": "2019-02-23T17:48:21.288363Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T17:48:22.774768Z",
     "start_time": "2019-02-23T17:48:21.299223Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Domain Space\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll.base import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T17:48:23.870548Z",
     "start_time": "2019-02-23T17:48:22.777572Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run targets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T17:48:23.943178Z",
     "start_time": "2019-02-23T17:48:23.873483Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "class Model:\n",
    "    __metaclass__ = ABCMeta\n",
    "    \n",
    "    def init_model(self, params):\n",
    "        self.model = self.get_model_class()\n",
    "        params.update(self.get_default_params())\n",
    "        params = self.resolve_params(params)\n",
    "        self.model = self.model(**params)\n",
    "        return self.model\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_model_class(self):\n",
    "        pass\n",
    "    \n",
    "    def get_default_params(self):\n",
    "        return {}\n",
    "    \n",
    "    def eval(self, eval_set, eval_metrics=None, verbose=False):\n",
    "        if eval_metrics == None:\n",
    "            eval_metrics = self.get_eval_metrics()\n",
    "        \n",
    "        result = pd.DataFrame({metric_name:[] for metric_name in eval_metrics})\n",
    "        for eval_name, eval_data in eval_set.iteritems():\n",
    "            y_pred = self.predict(eval_data[1])\n",
    "            y_true = eval_data[2]\n",
    "            \n",
    "            metric_scores = eval_class_metrics(y_true, y_pred, metrics=eval_metrics)\n",
    "            result = result.append(pd.Series(metric_scores, name=eval_name))\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def get_eval_metrics(self):\n",
    "        return ['auc', 'f1', 'acc', 'log_loss']\n",
    "    \n",
    "    def get_target_metric(self):\n",
    "        return 'acc'\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fit(self, X, y, eval_set, eval_names, eval_metrics, verbose=False):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self):\n",
    "        pass\n",
    "    \n",
    "    def resolve_params(self, params):\n",
    "        params_ = dict(params)\n",
    "        for k, v in params.iteritems():\n",
    "            if isinstance(v, dict):\n",
    "                params_.update(self.resolve_params(v))\n",
    "        return params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T17:48:23.985835Z",
     "start_time": "2019-02-23T17:48:23.945400Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NB(Model):\n",
    "    def __init__(self):\n",
    "        self.model_type = 'NB'\n",
    "        \n",
    "        self.hyperopt_scope = {\n",
    "            'priors' : hp.choice('priors', [None, [0.5, 0.5]])\n",
    "        }\n",
    "        \n",
    "    def get_model_class(self):\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        return GaussianNB\n",
    "    \n",
    "    def fit(self, X, y, eval_set, eval_metrics=None, verbose=False):\n",
    "        self.model = self.model.fit(X, y)\n",
    "        return self.eval(eval_set, eval_metrics=eval_metrics, verbose=verbose)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_attributes(model):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T17:48:24.042312Z",
     "start_time": "2019-02-23T17:48:23.993648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RFC(Model):\n",
    "    def __init__(self):\n",
    "        self.model_type = 'RFC'\n",
    "        \n",
    "        self.hyperopt_scope = {\n",
    "            'n_estimators'            : hp.choice('n_estimators', [3, 30, 100]),\n",
    "            'max_features'            : hp.choice('max_features', ['log2', 'sqrt']),\n",
    "            'criterion'               : hp.choice('criterion', ['gini', 'entropy']),\n",
    "            'bootstrap'               : hp.choice('bootstrap', [True, False])\n",
    "        }\n",
    "        \n",
    "        self.grid_scope = {\n",
    "            'n_estimators' : [50],\n",
    "            'max_features' : ['log2', 'sqrt', 0.1],\n",
    "            'criterion'    : ['entropy'],\n",
    "        }\n",
    "        \n",
    "    def get_model_class(self):\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        return RandomForestClassifier\n",
    "    \n",
    "    def get_default_params(self):\n",
    "        return {\n",
    "            'n_jobs'                  : -1,\n",
    "            'random_state'            : 0,\n",
    "            'verbose'                 : 1\n",
    "        }\n",
    "    \n",
    "    def fit(self, X, y, eval_set, eval_metrics=None, verbose=False):\n",
    "        self.model = self.model.fit(X, y)\n",
    "        print('model fitted')\n",
    "        return self.eval(eval_set, eval_metrics=eval_metrics, verbose=verbose)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_attributes(model):\n",
    "        return {\n",
    "            'feature_importances_': model.feature_importances_\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T17:48:24.086463Z",
     "start_time": "2019-02-23T17:48:24.045381Z"
    }
   },
   "outputs": [],
   "source": [
    "class BayesR(Model):\n",
    "    def __init__(self):\n",
    "        self.model_type = 'BayesR'\n",
    "        \n",
    "        self.hyperopt_scope = {\n",
    "            'tol'            : hp.choice('tol', [0.001, 0.0001, 0.00001]),\n",
    "            'alpha_1'        : hp.choice('alpha_1', [0.00001, 0.000001, 0.0000001]),\n",
    "            'alpha_2'        : hp.choice('alpha_2', [0.00001, 0.000001, 0.0000001]),\n",
    "            'lambda_1'       : hp.choice('lambda_1', [0.00001, 0.000001, 0.0000001]),\n",
    "            'lambda_2'       : hp.choice('lambda_2', [0.00001, 0.000001, 0.0000001])\n",
    "        }\n",
    "        \n",
    "        self.grid_scope = {\n",
    "            'tol' : [0.001, 0.0001, 0.00001]\n",
    "        }\n",
    "        \n",
    "    def get_model_class(self):\n",
    "        from sklearn.linear_model import BayesianRidge\n",
    "        return BayesianRidge\n",
    "    \n",
    "    def get_default_params(self):\n",
    "        return {\n",
    "            'n_iter'                  : 300,\n",
    "            'compute_score'           : False,\n",
    "            'copy_X'                  : False,\n",
    "            'fit_intercept'           : True,\n",
    "            'normalize'               : False,\n",
    "            'verbose'                 : True\n",
    "        }\n",
    "    \n",
    "    def fit(self, X, y, eval_set, eval_metrics=None, verbose=False):\n",
    "        self.model = self.model.fit(X, y)\n",
    "        return self.eval(eval_set, eval_metrics=eval_metrics, verbose=verbose)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_attributes(model):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T17:48:24.161343Z",
     "start_time": "2019-02-23T17:48:24.089178Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LR(Model):\n",
    "    def __init__(self):\n",
    "        self.model_type = 'LR'\n",
    "        \n",
    "        self.hyperopt_scope = {\n",
    "            'penalty'        : hp.choice('penalty', [\n",
    "                {\n",
    "                    'penalty': 'l2',\n",
    "                    'solver': 'sag'\n",
    "                }\n",
    "                # ,\n",
    "                # {\n",
    "                #     'penalty': 'l1',\n",
    "                #     'solver': 'liblinear'\n",
    "                # }\n",
    "            ]),\n",
    "            'tol'        : hp.choice('tol', [0.001, 0.0001, 0.00001]),\n",
    "            'C'          : hp.choice('C', [3, 10, 30, 100])\n",
    "        }\n",
    "        \n",
    "        self.grid_scope = {\n",
    "            'penalty'      : ['l2'],\n",
    "            'solver'       : ['sag'],\n",
    "            'C'            : [3, 10, 30, 100]\n",
    "        }\n",
    "        \n",
    "    def get_model_class(self):\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        return LogisticRegression\n",
    "    \n",
    "    def get_default_params(self):\n",
    "        return {\n",
    "            'dual'              : False,\n",
    "            'fit_intercept'     : True,\n",
    "            'intercept_scaling' : 1,\n",
    "            'max_iter'          : 100,\n",
    "            'multi_class'       : 'ovr',\n",
    "            'class_weight'      : None,\n",
    "            'random_state'      : 0,\n",
    "            'verbose'           : 1,\n",
    "            'warm_start'        : False,\n",
    "            'n_jobs'            : -1\n",
    "        }\n",
    "    \n",
    "    def fit(self, X, y, eval_set, eval_metrics=None, verbose=False):\n",
    "        self.model = self.model.fit(X, y)\n",
    "        return self.eval(eval_set, eval_metrics=eval_metrics, verbose=verbose)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_attributes(model):\n",
    "        return {\n",
    "            'n_iter_': model.n_iter_\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T17:48:24.226468Z",
     "start_time": "2019-02-23T17:48:24.163944Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVC(Model):\n",
    "    def __init__(self):\n",
    "        self.model_type = 'SVC'\n",
    "        \n",
    "        self.hyperopt_scope = {\n",
    "            'kernel'     : hp.choice('kernel', [\n",
    "                {\n",
    "                    'kernel': 'linear'\n",
    "                },\n",
    "                {\n",
    "                    'kernel': 'poly',\n",
    "                    'degree': hp.choice('degree', [1,2,3,4]),\n",
    "                    'coef0' : hp.choice('coef0_poly', [0, 1, 3, 10])\n",
    "                },\n",
    "                {\n",
    "                    'kernel': 'rbf'\n",
    "                },\n",
    "                {\n",
    "                    'kernel': 'sigmoid',\n",
    "                    'coef0' : hp.choice('coef0_sig', [0, 1, 3, 10])\n",
    "                }\n",
    "            ]),\n",
    "            'shrinking'    : hp.choice('shrinking', [True, False]),\n",
    "            'probability'  : hp.choice('probability', [True, False]),\n",
    "            'tol'        : hp.choice('tol', [0.00001, 0.000001, 0.0000001]),\n",
    "            'C'          : hp.choice('C', [0.1, 0.3, 1, 3, 10])\n",
    "        }\n",
    "        \n",
    "    def get_model_class(self):\n",
    "        from sklearn.svm import SVC\n",
    "        return SVC\n",
    "    \n",
    "    def get_default_params(self):\n",
    "        return {\n",
    "            'gamma'             : 'auto',\n",
    "            'max_iter'          : 1000,\n",
    "            'random_state'      : 0,\n",
    "            'verbose'           : 1\n",
    "        }\n",
    "    \n",
    "    def fit(self, X, y, eval_set, eval_metrics=None, verbose=False):\n",
    "        self.model = self.model.fit(X, y)\n",
    "        return self.eval(eval_set, eval_metrics=eval_metrics, verbose=verbose)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_attributes(model):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T17:48:52.157068Z",
     "start_time": "2019-02-23T17:48:52.102917Z"
    }
   },
   "outputs": [],
   "source": [
    "class LightGBM(Model):\n",
    "    def __init__(self):\n",
    "        self.model_type = 'LightGBM'\n",
    "        \n",
    "        self.hyperopt_scope = {\n",
    "            'boosting': hp.choice('boosting', [\n",
    "                {\n",
    "                    'boosting': 'gbdt'\n",
    "                },\n",
    "                {\n",
    "                    'boosting': 'rf'\n",
    "                },\n",
    "                {\n",
    "                    'boosting': 'dart',\n",
    "                    'drop_rate': hp.uniform('drop_rate', 0, 1),\n",
    "                    'skip_drop': hp.uniform('skip_drop', 0, 1),\n",
    "                    'uniform_drop': hp.uniform('uniform_drop', [True, False])\n",
    "                },\n",
    "                {\n",
    "                    'boosting': 'goss',\n",
    "                    'top_rate': hp.uniform('top_rate', 0, 1),\n",
    "                    'other_rate': hp.uniform('other_rate', 0, 1)\n",
    "                }\n",
    "            ]),\n",
    "            'learning_rate': hp.loguniform('learning_rate', np.log(0.00001), np.log(0.1)),\n",
    "            'n_estimators'            : hp.choice('n_estimators', [3, 30, 100]),\n",
    "            'max_features'            : hp.choice('max_features', ['log2', 'sqrt']),\n",
    "            'criterion'               : hp.choice('criterion', ['gini', 'entropy']),\n",
    "            'bootstrap'               : hp.choice('bootstrap', [True, False])\n",
    "        }\n",
    "        \n",
    "        self.grid_scope = {\n",
    "            'n_estimators' : [50],\n",
    "            'max_features' : ['log2', 'sqrt', 0.1],\n",
    "            'criterion'    : ['entropy'],\n",
    "        }\n",
    "        \n",
    "    def get_model_class(self):\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        return RandomForestClassifier\n",
    "    \n",
    "    def get_default_params(self):\n",
    "        return {\n",
    "            'objective'             : 'binary',\n",
    "            'metric'                : ['binary_error'],\n",
    "            'num_iterations'        : 1000,\n",
    "            'early_stopping_round'  : 100,\n",
    "            'verbosity'             : 1,\n",
    "            'metric_freq'           : 10,\n",
    "            'seed'                  : 0\n",
    "        }\n",
    "    \n",
    "    def fit(self, X, y, eval_set, eval_metrics=None, verbose=False):\n",
    "        self.model = self.model.fit(X, y)\n",
    "        print('model fitted')\n",
    "        return self.eval(eval_set, eval_metrics=eval_metrics, verbose=verbose)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_attributes(model):\n",
    "        return {\n",
    "            'feature_importances_': model.feature_importances_\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/9e0e96b406b4b4d69c9a4ae27d55ee3c"
  },
  "gist": {
   "data": {
    "description": "models.ipynb",
    "public": false
   },
   "id": "9e0e96b406b4b4d69c9a4ae27d55ee3c"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
